{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9N9EGXKJ1l5hQGLchp64H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedGhassenBouallegue/Text-Minning/blob/main/DetectionOfComplaintTweetsModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfzMER5Yfslv",
        "outputId": "0b1e63d1-e82b-4b21-ef8b-06e20d54f1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGOrnAwOe12C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe32918-5a22-452b-a8a0-6d0c04b6eeb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id    airline                                              tweet\n",
            "0   80938     United  @united I'm having issues. Yesterday I rebooke...\n",
            "1   10959     United  @united kinda feel like the $6.99 you charge f...\n",
            "2  130813  SouthWest  Livid in Vegas, delayed, again&amp; again&amp;...\n",
            "3  146589     United  @united the most annoying man on earth is on m...\n",
            "4  117579     United  @united The last 2 weeks I've flown wit u, you...\n",
            "     id    airline                                              tweet\n",
            "0   404     United  @brianfadem @united The best summertime soap o...\n",
            "1   706  SouthWest  @aresef @united yes the change fees are cheape...\n",
            "2   882  SouthWest  @SouthwestAir Do you guys not fly from Birming...\n",
            "3  1196     United  This mornings @united #flight seems to be on t...\n",
            "4  1244    JetBlue  @JetBlue @Boston_Calling I have never been to ...\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "df_complaint = pd.read_csv('complaint1700.csv')\n",
        "df_noncomplaint = pd.read_csv('noncomplaint1700.csv')\n",
        "print(df_complaint.head())\n",
        "print(df_noncomplaint.head())\n",
        "df_test=pd.read_csv('test_data.csv')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text"
      ],
      "metadata": {
        "id": "dFUBhA4cmB2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose either stemming or lemmatization\n",
        "def stem_and_lemmatize(text):\n",
        "    words = text.split()\n",
        "    # Uncomment one of the following lines to choose stemming or lemmatization\n",
        "    # words = [stemmer.stem(word) for word in words if word not in stop_words]  # Stemming\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "SD2NAyC-qwSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_noncomplaint['tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPB63xounOe5",
        "outputId": "cc7847d5-e174-4ac1-d141-0f34acbd90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       @brianfadem @united The best summertime soap o...\n",
            "1       @aresef @united yes the change fees are cheape...\n",
            "2       @SouthwestAir Do you guys not fly from Birming...\n",
            "3       This mornings @united #flight seems to be on t...\n",
            "4       @JetBlue @Boston_Calling I have never been to ...\n",
            "                              ...                        \n",
            "1695    @SubTheGamer @united completely pathetic! I'm ...\n",
            "1696    @QuranWeekly @united  Too many bigots in Ameri...\n",
            "1697    @SangyeH @united I would too. My sister conver...\n",
            "1698    Ã¢â‚¬Å“@hindukid1021: prime example of our wor...\n",
            "1699    @united @ImamSuhaibWebb you call that a statem...\n",
            "Name: tweet, Length: 1700, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean text\n",
        "df_noncomplaint['cleaned_tweet'] = df_noncomplaint['tweet'].apply(clean_text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df_noncomplaint['cleaned_tweet'] = df_noncomplaint['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "# Check cleaned text\n",
        "#print(df_noncomplaint[['tweet', 'cleaned_tweet']].head())\n",
        "df_noncomplaint['processed_tweet'] = df_noncomplaint['cleaned_tweet'].apply(stem_and_lemmatize)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#clean text\n",
        "df_complaint['cleaned_tweet'] = df_complaint['tweet'].apply(clean_text)\n",
        "\n",
        "df_complaint['cleaned_tweet'] = df_complaint['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "# Check cleaned text\n",
        "#print(df_complaint[['tweet', 'cleaned_tweet']].head())\n",
        "\n",
        "df_complaint['processed_tweet'] = df_complaint['cleaned_tweet'].apply(stem_and_lemmatize)\n",
        "\n",
        "\n",
        "#print(df_noncomplaint[['tweet', 'processed_tweet']].head())\n",
        "#print(df_complaint[['tweet', 'processed_tweet']].head())\n",
        "\n",
        "df_test['cleaned_tweet'] = df_test['tweet'].apply(clean_text)\n",
        "\n",
        "df_test['cleaned_tweet'] = df_test['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "df_test['processed_tweet'] = df_test['cleaned_tweet'].apply(stem_and_lemmatize)\n",
        "print(df_test[['tweet', 'processed_tweet']].head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47T8GRDymlql",
        "outputId": "3ea468f0-f403-4525-bbff-86ed112c38a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  \\\n",
            "0  @SouthwestAir get your damn act together. Don'...   \n",
            "1  @AmericanAir horrible at responding to emails....   \n",
            "2  @AmericanAir hey where is your crew? Flight aa...   \n",
            "3         Ok come on we are late let's goooo @united   \n",
            "4  @AmericanAir since you are now affiliated with...   \n",
            "\n",
            "                                     processed_tweet  \n",
            "0  southwestair get damn act together dont announ...  \n",
            "1  americanair horrible responding email ive sent...  \n",
            "2  americanair hey crew flight aa im going miss f...  \n",
            "3                      ok come late let goooo united  \n",
            "4  americanair since affiliated usairways wanted ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Features Using the TF-IDF Model"
      ],
      "metadata": {
        "id": "eTg7jKqurk89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_complaint['label'] = 1\n",
        "df_noncomplaint['label'] = 0\n",
        "df = pd.concat([df_noncomplaint, df_complaint], ignore_index=True)\n",
        "\n",
        "print(df.head(2000))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dgvVTkV2rcO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d80938-7854-4b96-d702-5987453bbdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          id    airline                                              tweet  \\\n",
            "0        404     United  @brianfadem @united The best summertime soap o...   \n",
            "1        706  SouthWest  @aresef @united yes the change fees are cheape...   \n",
            "2        882  SouthWest  @SouthwestAir Do you guys not fly from Birming...   \n",
            "3       1196     United  This mornings @united #flight seems to be on t...   \n",
            "4       1244    JetBlue  @JetBlue @Boston_Calling I have never been to ...   \n",
            "...      ...        ...                                                ...   \n",
            "1995   35219     United  @united Yeah, but now I'm waiting for a 3 hour...   \n",
            "1996   11793     United  @united When is a cancelled flight not cancelled?   \n",
            "1997  170083   American  Longg morning @dfwairport. Runway closed bec d...   \n",
            "1998   38205      Delta  @DeltaAssist @Delta I made the orig. reservati...   \n",
            "1999   58369  SouthWest  .@SouthwestAir Your Wifi is terrible. http://t...   \n",
            "\n",
            "                                          cleaned_tweet  \\\n",
            "0     brianfadem united best summertime soap opera b...   \n",
            "1     aresef united yes change fees cheaper seems li...   \n",
            "2     southwestair guys fly birmingham richmond site...   \n",
            "3     mornings united flight seems time least never ...   \n",
            "4     jetblue boston_calling never boston would love...   \n",
            "...                                                 ...   \n",
            "1995  united yeah im waiting hour delayed departure ...   \n",
            "1996                  united cancelled flight cancelled   \n",
            "1997  longg morning dfwairport runway closed bec dra...   \n",
            "1998  deltaassist delta made orig reservation oct wa...   \n",
            "1999         southwestair wifi terrible httptcoecqggpiq   \n",
            "\n",
            "                                        processed_tweet  label  \n",
            "0     brianfadem united best summertime soap opera b...      0  \n",
            "1     aresef united yes change fee cheaper seems lik...      0  \n",
            "2     southwestair guy fly birmingham richmond site ...      0  \n",
            "3     morning united flight seems time least never k...      0  \n",
            "4     jetblue boston_calling never boston would love...      0  \n",
            "...                                                 ...    ...  \n",
            "1995  united yeah im waiting hour delayed departure ...      1  \n",
            "1996                  united cancelled flight cancelled      1  \n",
            "1997  longg morning dfwairport runway closed bec dra...      1  \n",
            "1998  deltaassist delta made orig reservation oct wa...      1  \n",
            "1999         southwestair wifi terrible httptcoecqggpiq      1  \n",
            "\n",
            "[2000 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['processed_tweet']\n",
        "y=df['label']\n",
        "x_test = df_test['processed_tweet']\n",
        "\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "x_tfidf=tfidf.fit_transform(x)\n",
        "\n",
        "x_test_tfidf = tfidf.fit_transform(x_test)\n",
        "\n",
        "print(x_tfidf.shape)\n",
        "\n",
        "print(x_test_tfidf.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACd1hl-V8xZK",
        "outputId": "d6ee4349-559c-47e2-e916-d1628b01a91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3400, 5000)\n",
            "(4555, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(x_tfidf, y)\n",
        "\n",
        "#df_test->cleaning->tfidf_transform\n",
        "y_pred = nb.predict(x_test_tfidf)\n",
        "\n",
        "df_test['predicted_label'] = y_pred\n",
        "\n",
        "print(df_test[['tweet', 'predicted_label']].head(10))\n",
        "\n",
        "\n",
        "df_test['label'] = 1\n",
        "y_test = df_test['label']\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlKQeq9QBiXf",
        "outputId": "e5e572a7-e317-45e4-ca9c-735ca74a77a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  predicted_label\n",
            "0  @SouthwestAir get your damn act together. Don'...                0\n",
            "1  @AmericanAir horrible at responding to emails....                1\n",
            "2  @AmericanAir hey where is your crew? Flight aa...                1\n",
            "3         Ok come on we are late let's goooo @united                0\n",
            "4  @AmericanAir since you are now affiliated with...                1\n",
            "5  @IIJERiiCHOII @VirginAmerica what the fuck is ...                0\n",
            "6  @SouthwestAir your customer service sucks! You...                0\n",
            "7  Rudest, most condescending customer service re...                0\n",
            "8  @SouthwestAir flight 195 delayed. So much for ...                1\n",
            "9              @UtdArif @AmericanAir this is so shit                1\n",
            "Accuracy: 37.28%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.37      0.54      4555\n",
            "\n",
            "    accuracy                           0.37      4555\n",
            "   macro avg       0.50      0.19      0.27      4555\n",
            "weighted avg       1.00      0.37      0.54      4555\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}